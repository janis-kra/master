% !TEX root = ../thesis.tex
%
\chapter{Implementation}
\label{ch:implementation}

This chapter describes details about the implementation and configuration of the passive user feedback system.
Appendix \cref{ch:appendix:source} contains the source code of the services and applications that were created over the course of this thesis; these are also available via GitHub\footnote{\url{https://github.com/janis-kra/master-impl}}\todo{link to "final" tag when done}.

\section{Service Orchestration}
\label{sec:implementation:orchestration}

All services run in their own Docker containers in order to facilitate distribution of the system.
Orchestration of the containers is done via \emph{Docker Compose} (short \emph{Compose}), which offers a straightforward way of describing the services of an application and how they interact with each other in a single file (cf. \cref{appendix:code:docker:docker-compose} for the source code of the \texttt{docker-compose.yml} file).
???

Docker allows to assign each container a custom network which allows for virtualization of distinct and separated networks even though the containers are all on the same server.
This is done via the \texttt{networks} setting for all container definitions, in this case setting the network to \texttt{feedback-net}.
The \texttt{feedback-net} network is a default bridge network, which means that it is an isolated network running in its respective Docker host.
Containers running on the same Docker host and bridge network are thus able to communicate with each other via another containers IP address or name.
For example, client application can post events to the Event Store instance via the URL \texttt{http://eventstore:2113/}, where the port 2113 denotes the port at which the Event Store container exposes its \ac{HTTP} interface.

...

\subsection{Operating the System}

The final setup of \ac{IFAS} enables the following Compose commands, which can either be issued with a specific service name, or without this parameter which causes the command to be executed for all applicable services:

\begin{itemize}
\item Create and start containers for the services defined in the Compose file, via \texttt{docker-compose up [service]}; the additional \texttt{-d} parameter runs the containers in detached mode, i.e. in the background
\item Start the containers that are already created, via \texttt{docker-compose start [service]}
\item Stop and remove containers defined in the Compose file, as well as their volumes and networks, via \texttt{docker-compose down}
\item Stop containers defined in the Compose file, via \texttt{docker-compose stop}
\item Show logging information for a container, via \texttt{docker-compose logs [service]}; the additional \texttt{-f} parameter follows the logs as new ones appear, instead of just printing them once to the  console
\end{itemize}

A user of \ac{IFAS} would usually create and start the containers via \texttt{docker-compose up -d} and then optionally attach to the logs via \texttt{docker-compose logs -f}.
If the system or specific services would have to be taken offline, this could be done via \texttt{docker-compose down}.
For example, the Elasticsearch container would be stopped via \texttt{docker-compose stop elasticsearch}.
Subsequently, the Elasticsearch container would be started again via the \texttt{start} command if no changes to the container are made, e.g. via its service definition, or via the \texttt{up} command if the container has to be recreated.
The \texttt{down} command should only be used if a backup of the relevant Docker volumes was made -- otherwise, all data would be lost.

\subsection{Clustering}

...

\section{Client Application}
\label{sec:implementation:client}

\subsection{Implementing Click Tracking}
\label{subsec:implementation:client:problems}

When tracking clicks in a web application, the technical idiosyncrasies of reliably sending data via \ac{XHR} requests using JavaScript can become problematic.
For various reasons, which are discussed below, there are no valid alternatives to doing asynchronous \ac{XHR} requests for click tracking for this use case though.

The gist of the problem is that when a user clicks a link in a web application, this normally introduces a redirect to a new page, therefore potentially aborting the asynchronous \ac{XHR} request\cite{Kohavi2010}.
This problem could be solved by doing a synchronous request instead of an asynchronous one, but this is not a desirable solution for two reasons.
First, the whole web application blocks for the duration of the request; if the user's internet connection is slow -- e.g .when accessing the application on a mobile phone -- or the logging server is experiencing heavy load, this can introduce a noticeable and annoying delay.
These delays can be a reason to make the user abandon the application altogether\cite{Kohavi2010,Dmitriev2017}.

In order to mitigate these problems, the Navigator \ac{API} of modern browsers was extended with the \texttt{sendBeacon}\footnote{\url{https://developer.mozilla.org/en-US/docs/Web/API/Navigator/sendBeacon}} method, but this cannot be used for this use case for two reasons.
The concept of the \texttt{sendBeacon} method is that it can be used to asynchronously send a small amount of data to a server prior to the user leaving the page, in a reliable way.
However, this is not implemented yet in all modern browsers\footnote{\url{https://caniuse.com/\#feat=beacon}}, especially Internet Explorer and the desktop and mobile Safari browsers.
Also, when posting data to Event Store using its \ac{HTTP} \ac{API}, the \texttt{ES-EventId} header has to be attached to the request with a unique id.
Attaching custom headers via the \texttt{sendBeacon} method is not supported though.

For the reasons discussed above, a standard asynchronous \ac{XHR} is the best alternative.
This would introduce click data being lost when the request is dropped, but as the Mattermost chat application used as the client here is a \ac{SPA}, this is not a problem.

Technically, there exist three different click event types: \texttt{mousedown}, \texttt{mouseup} and \texttt{click}.
Capturing the event on \texttt{mousedown} would cause the event to fire earlier than the two other event types, but this is not necessary as problems with lost click events are not expected because Mattermost is a \ac{SPA}.

\section{Storage Configuration}
\label{sec:implementation:storage}

The storage layer of the passive user feedback system is realized via the event store reference implementation (\cref{sec:classifications:storage}).
An officially maintained Docker image\footnote{\url{https://hub.docker.com/r/eventstore/eventstore/}} is used as the starting point and requires little additional configuration.
The relevant lines from the \texttt{docker-compose.yml} file are listed in \todo{cref to code listing here}.

% code listing: docker-compose.yml#eventstore

This spins up a EventStore container with mostly default settings, which could be further configured via ?.
\todo{explain what could be configured+what the default settings are}

Aside from specifying the image base and its name, these settings make the EventStore's TCP and HTTP interfaces available via ports 1113 and 2113.
The container can be accessed by other containers via its name, \texttt{eventstore}.
Thus, the client application can post events via HTTP to \url{http://evenstore:2113}, while the bridge to the aggregation service (cf. \cref{sec:implementation:bridge}) listens to new events via the TCP address \url{tcp://eventstore:1113}.

\section{Storage-Aggregation Bridge}
\label{sec:implementation:bridge}

Because Elasticsearch does not have dedicated support for importing data from an event store, an additional service had to be implemented which serves as a bridge between the two services.

\subsection{Implementing Mapping of Advanced Event Store Features to Elasticsearch}
\label{subsec:implementation:bridge:mapping}

WIP

\section{Aggregation Service}
\label{sec:implementation:aggregation}

\section{Analysis Application}
\label{sec:implementation:analysis}

